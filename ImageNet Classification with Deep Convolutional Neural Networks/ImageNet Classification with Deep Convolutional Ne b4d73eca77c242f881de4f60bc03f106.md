# ImageNet Classification with Deep Convolutional Neural Networks

Alex팀은 imageNet LSVRC-2010에서  top1-35.7%,top5-17%의 error rate를 달성하였다

또한 LSVRC-2012에서는 top1-36.7%, top5-15.3%의  error rate를 달성하였다

위의 대회에서 효율적인 GPU구현을 사용하였고 ‘drop out’이라는 정규화 방법을 사용하였다

**introduction**

객체 인식에 대한 접근방식은 machine learning방법이 필수적이다

최근까지 labled images의 datasets들은 상대적으로 매우 적었다.

그래서 MNIST detaset같이 label-preserving transformations로 증강된 경우  간단한 인식 작업은 잘 수행할 수 있었다.

그러나 실제 사물은 상당한 가변성을 나타내므로 더 큰 훈련세트를 사용해야 한다.

그래서 최근에서야 가능해진 ImageNet이라는 2만2천개가 넘는 카테고리,1500만장이 넘는 고해상도의 labled dataset이 등장하게 된다

이에따라 학습용량이 큰 모델이 필요하다

CNN모델은 depth나 breadth을 제어 가능하고 이미지특성을 제어하는 거에서 강력하고 정확하게 추측을 한다

또한 feedforward network와 다르게 더 적은 connection과 매개변수를 가지기 때문에 훈련하기가 더 쉽지만 이론적으로는 약간 떨어질 가능성이 있다

(다행히 최근 GPU성능 때문에 비용이나 과대적합면에서  ImageNet같은 최신 데이터세트를 교육할 수 있다)

이 논문이 기여한 바는 다음과 같다

-가장 큰 CNN중 하나를 학습시켜 ILSVRC-2010과 ILSVRC-2012에서 큰 성과를 내었다

-2D컨볼루션의 고도로 최적화된 GPU구현과 컨볼루션 신경망 훈련에 내재된 다른 모든 작업을 공개적으로 제공함

-이 네트워크에는 성능을 개선,교육시간을 줄임,새롭고 특이한 기능이 많이 포함되어 있다

-overfitting을 방지하기 위한 효과적인 기술

-5개의 컨볼루션 레이어 3개의 fully connected레이어 중 어느 하나를 제거(?)어느 하나가 수행능력에 열악함을 준다는 것

**The Dataset**

이미지넷은 22000가지,1500만장 이상의 고해상도 데이터셋이다

2010년에 시작된 lLSVRC는 1000개 범주에 1000개의 이미지가 있는 image net의 하위집합을 사용한다

훈련 이미지-120만장,검증 이미지-5만장,테스트이미지-15만장

image net에서는 상위 1,5의 두 가지 오류율을 보고하는 것이 일반적이다

image net은 가변 해상도 이미지로 구성되는 반면 이 시스템에서는 일정한 입력 차원이 필요,

그래서 256x256고정 해상도로 다운 샘플링을 하였다

(가로나 세로 중 작은 쪽 하나를 256으로 줄인 후 센터를 256x256으로 잘라 모델의 입력으로 사용)

이거 말고는 다른 전처리는 안했다

(이게 음 centerize(?))

**The Architecture(시스템의 동작 원리)**

이 아키텍처에는 8개의 학습된 레이어(5개는 컨볼루션,3개는 완전 연결 레이어)

ReLU Nonlinearity

원래 표준 뉴런결과함수로서는 sigmoid랑 tanh함수다(하이퍼볼릭 탄젠트)

경사하강법에서, saturating nonlinearities를 사용하는 것보다 non-saturating nonlinearities 인 ReLU를 사용하는 것이 학습 속도 측면에서 훨씬 빠르다
saturating(양의 무한대,음의 무한대로 갈수록 기울이가 0에 수렴한다는 것)

![스크린샷 2023-03-02 오후 5.35.00.png](ImageNet%20Classification%20with%20Deep%20Convolutional%20Ne%20b4d73eca77c242f881de4f60bc03f106/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.35.00.png)

점선 - 하이퍼볼릭 탄젠트

실선 - ReLu

점선(하이퍼볼릭 탄젠트)보다 실선(ReLU)를 사용하는 것이 학습 에러율을 25%낮추는데 시간이 6배 빠르다고 함 ,다른 어떤 정규화도 안했다고 함

위 그림은 기존 포화뉴런모델을 사용했다면 이렇게 큰 신경망을 학습 못했을거라고 함

non-saturating 활성함수의 사용은 얘네가 처음은 아니다. 이전에 |tanh(x)| 와 같은 함수를 Jarrettet ai에서  위의 함수를 통해 오버피팅을 방지했다는 발표가 있었다. 그러나 여기서 주 관심사는 오버피팅(과적합)을 방지하는 거였다

더 빠른 학습은 대규모 데이터세트에서 훈련된 대형 모델의 성능에 큰 영향을 미친다

**Training on Multiple GPUs**

단일 GTX580 GPU 는 메모리가 3GB →학습할 수 있는 네트워크의 최대크기가 제한됨

여기서 저자들은 2개의 GPU를 병렬적으로 사용

딥러닝의 특정 레이어에서만 2개의 GPU가 서로 데이터를 교환할 수 있게 만들고 나머지 레이어에서는 같은 GPU로부터 연산을 이어받을 수 있게 만들었다(뭔말인지 몰라서 찾아보고 다른곳에서 인용)

결과 아키텍처는 ‘colummar’CNN의 아키텍처와 유사(열이 독립적이지 않다는 거만 다르다)

**Local Response Normalization**

ReLU는 포화를 방지하기 위해 입력 정규화가 필요하지 않다는 속성을 가짐

그러나 다음과 같은 로컬 정규화 체계가 일반화에 도움이 될 수 있다

![스크린샷 2023-03-02 오후 7.10.30.png](ImageNet%20Classification%20with%20Deep%20Convolutional%20Ne%20b4d73eca77c242f881de4f60bc03f106/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_7.10.30.png)

k,n,a,B는 하이퍼 하라미터, 수치는 이 논문에서는 

k=2,n=5,a=10−4,B=0.75로 설정함

(단, 측정 레이어에서만 사용 > ReLU를 거치고 난 결괏값에)

이 정규화 방법을 통해 Top1 에러율은 1.4% 감소, Top5 에러율은 1.2% 감소

**Overlapping Pooling(뭔 말인지 몰라서 다른 곳에서 찾아보고 인용)**

기존에 CNN에서는 Pooling을 진행할 때, pooling unit들이 겹쳐져서 연산되는 것이 아니라 겹치지 않게 연산이 이루어졌다. 저자들은 하지만, 저자들은 겹쳐서 pooling 연산을 수행
하여 Top-1 에러율을 0.4%, Top-5 에러율을 0.3% 감소시켰다고 한다. (stride = 2, kernel = 3 x 3 사용)

![스크린샷 2023-03-02 오후 7.15.59.png](ImageNet%20Classification%20with%20Deep%20Convolutional%20Ne%20b4d73eca77c242f881de4f60bc03f106/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_7.15.59.png)

**Overall Architecture**

가중치가 있는 8개의 레이어가 있다.처음 5개는 컨볼루션,나머지3개는 완전연결(1000개의 클래스로 분류되는 softmax연산을 거쳐서 최종적으로 1000개의 객체를 분류 가능)

컨볼루션 레이어에서 2, 4, 5번째 레이어는 바로 이전의 GPU에서 연산된 결과를 그대로 가져와서 사용하는 반면, 3번째 레이어에서는 GPU간의 communication을 통해 이전 레이어에서 연산된 2개의 GPU 결과를 모두 받아오도록 만든 것을 확인할 수 있다. (3번째 레이어에서 점선이 교차되어서 그려진 것을 볼 수 있다.)

![스크린샷 2023-03-02 오후 7.21.25.png](ImageNet%20Classification%20with%20Deep%20Convolutional%20Ne%20b4d73eca77c242f881de4f60bc03f106/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_7.21.25.png)

완전연결 레이어는 이전 레이어의 뉴런을 모두 연결,

Response Normalization은 컨볼루션 레이어의 1번째와 2번째 레이어에서 사용,

 Overlapping Pooling을 진행하는 Max pool과정은 Convolution 레이어의 1번째, 2번째 그리고 마지막인 5번째 레이어에서 사용,

 활성함수로 사용된 ReLU는 모든 레이어(5개의 컨볼루션 3개의 완전연결)사용

첫번째 컨볼루션 레이어

입력 이미지: 224x224x3

커널 : 11x11x3

두번째 컨볼루션 레이어

입력 이미지 : 전 층의 입력이미지 출력

커널 : 5x5x48

세번쨰 컨볼루션 레이어

입력이미지 :

커널 : 3x3x256

네번쨰 컨볼루션 레이어

입력이미지 : 

커널 : 3x3x192

다섯번째 컨볼루션 레이어

입력이미지:

커널:3x3x192

완전연결계층에는 4096개의 뉴런이 있다

**Reducing Overfitting**

여기에서 신경망 아키텍쳐에는 6000만개의 매개변수(파라미터)가 있다

두 기본 방법이 있다(오버피팅을 방지하는)

1.Data Augmentation

첫번째

오버피팅을 방지하기 위한 가장 쉽고 좋은 방법은 레이블 보존 변환을 사용하여 데이터 집합을 인위적으로 확대하는 것이다

여기서 두가지 데이터 증가 방식을 사용하는데,둘 다 약간의 계산으로 원본 이미지에서 변환된 이미지를 생성,변환된 이미지를 디스크에 저장할 필요가 없다

첫번째는 좌우반전!

임의의 256x256이미지에서 임이의 224x224크기의 패치를 얻어 입력으로 사용

이렇게 되면 32x32x2 (2048)배만큼 데이터를 늘릴 수 잇게 됨

테스트에서는 224x224와 반전에서 뽑은 5개 패치를 사용해 10패치를 입력으로 사용

이 10개 패치 결과를 평균 내어 최종 아웃풋으로 산출

두번째

RGB채널의 색상강도를 조절하는 방법

PCA(주성분 분석이라고 함) 를 진행,평균은 0 표준편차는 0.1을 갖는 가우시안 분포에서 무작위로 추출,원래의 픽셀값에 곱해주어 색상의 변형을 줌

2.Dropout

정방향 전달에 기여하지 않으며 역전파에 참여하지 않음 즉 입력이 제공될 때마다 신경망은 다른 아키텍쳐를 샘플링 하지만 모든 아키텍처는 가중치를 공유한다

정리하자면….

사용자가 지정한 확률을 근거로 특정 뉴런에 신호전달x

![스크린샷 2023-03-02 오후 9.50.01.png](ImageNet%20Classification%20with%20Deep%20Convolutional%20Ne%20b4d73eca77c242f881de4f60bc03f106/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_9.50.01.png)

**Details of learning(이 부분은 도저히 이해가 안되서 다른글을 많이 살펴보고 인용)**

- Stochastic Gradient Descent 활용
- Batch Size - 128
- Momentum - 0.9
- Weight Decay - 0.005
- Weight Initialization - zero mean Gaussian distribution 활용, 표준편차 0.01
- Bias Initialization - Layer에 따라 1 또는 0으로 설정, 1로 설정한 이유는 ReLU값에 양수를 부여하면서 학습을 촉진시키는 역할을 하기 때문
- Learning Rate - 0.01로 진행하면서 training시 조정. 조정 방법은 0.01을 10씩 나누면서 진행되었음.
    
    ![스크린샷 2023-03-02 오후 10.39.12.png](ImageNet%20Classification%20with%20Deep%20Convolutional%20Ne%20b4d73eca77c242f881de4f60bc03f106/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-03-02_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_10.39.12.png)
    

 물체가 가운데에 있지 않아도 detection이 용이했다는 점, Euclidean distance(수학에서 흔히 말하는 두 점 사이의 거리를 계산할 때 쓰이는 방법)를 계산하여 거리가 짧을 수록 유사한 사물로 인지했다는 점은 괄목할 만한 성과였다. 그러나 당시 GPU들의 성능이 좋지 않았다는 점, layer 하나하나가 결과를 도출하는 데에 큰 영향을 미쳤다는 점 등에서 한계가 존재했다. 그럼에도 불구하고 Alexnet은 CNN 분야의 초석이며, CNN의 혁신을 불러일으켰다고 보아도 무방하다. Alexnet의 기본적인 구조를 바탕으로 하여 추후 프레임워크들도 발전하였기 때문이다